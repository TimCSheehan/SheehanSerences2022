{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import circ_corr as cc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import scipy\n",
    "pi=np.pi\n",
    "subjs = ['UCSD0' + x for x in ['54','60','61','62','63','64']]\n",
    "rois = ['V1','V2','V3','V3AB','hV4','IPS0']\n",
    "n_subj=len(subjs)\n",
    "\n",
    "def sem_plot(x,y,axs=0,within_E=0,do_line=1,**args):\n",
    "    # x is assumed to be examples x len(y)\n",
    "    n_ex,n_points =  y.shape\n",
    "    if n_points!=len(x):\n",
    "        y=y.T\n",
    "        n_ex,n_points =  y.shape\n",
    "    assert n_points==len(x), 'x not correct shape'\n",
    "    m_y = np.mean(y,0)\n",
    "    if within_E:\n",
    "        y_use = (y.T-np.mean(y,1)).T\n",
    "        s_y = np.std(y_use,0)/np.sqrt(n_ex)\n",
    "    else:\n",
    "        s_y = np.std(y,0)/np.sqrt(n_ex)\n",
    "    if axs==0:\n",
    "        plt.fill_between(x,m_y-s_y,m_y+s_y,**args)\n",
    "        if do_line:\n",
    "            plt.plot(x,m_y,'k')\n",
    "    else:\n",
    "        axs.fill_between(x,m_y-s_y,m_y+s_y,**args)\n",
    "        if do_line:\n",
    "            axs.plot(x,m_y,'k')\n",
    "    \n",
    "import matplotlib \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "import matplotlib\n",
    "cmap = matplotlib.cm.get_cmap('Dark2')\n",
    "ct = cmap(np.linspace(0,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sav_fig(nam):\n",
    "    root = './Figs_v5/'\n",
    "    plt.savefig(root + nam +'.svg',dpi=1200)\n",
    "    \n",
    "def circ_mean_rad(x): return np.angle(np.mean(np.exp(1j*x))) # rad --> rad\n",
    "def circ_mean(x): return np.angle(np.mean(np.exp(1j*x/90*pi)))*90/pi # deg --> deg\n",
    "def circ_std(x):\n",
    "    R = np.abs(np.mean(np.exp(1j*x/90*pi)))\n",
    "    v = np.sqrt(-2*np.log(R))\n",
    "    return v\n",
    "def inv_cdf(cdf,probe): return np.argmin(np.abs(np.expand_dims(cdf,1) - probe),0) # draws from 'y'-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Implement:\n",
    "1. fitting a subject iteratively with cross-validation\n",
    "1. evaluating goodness of fit(?) relative to null model?\n",
    "\n",
    "Later Add\n",
    "1. Fitting function 1 using max likelihood! \n",
    "1. Poisson noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bining(bns,overlap,grouping_var,var,var2=[-999],flip=1,prior_gauss=[4,0],want_var=0):\n",
    "#     global obs, d_use_rad\n",
    "    n_bns=len(bns)\n",
    "    grouper = np.zeros(len(bns))\n",
    "    if var2[0]!=-999:\n",
    "        do_SDT=1\n",
    "\n",
    "        out = np.zeros((2,len(bns)))\n",
    "            \n",
    "        if flip:\n",
    "            grouping_var = np.concatenate((grouping_var,-grouping_var))\n",
    "            var = np.concatenate((var,(var==0)*1))\n",
    "            var2 = np.concatenate((var2,-var2))\n",
    "    else:\n",
    "        do_SDT=0\n",
    "        out = np.zeros(len(bns))\n",
    "        if flip:\n",
    "            grouping_var = np.concatenate((grouping_var,-grouping_var))\n",
    "            if flip==2:\n",
    "                var = np.concatenate((var,var))\n",
    "            elif flip==1:\n",
    "                var = np.concatenate((var,-var))\n",
    "    for i in range(n_bns):\n",
    "        if overlap==0:\n",
    "            if i==(n_bns-1):\n",
    "                continue\n",
    "            else:\n",
    "                these_ind = (grouping_var>=bns[i])&(grouping_var<bns[i+1])\n",
    "            \n",
    "        elif i<overlap:\n",
    "            these_ind = (grouping_var<=bns[i+overlap]) | (grouping_var>=bns[i-overlap])\n",
    "        elif i>(n_bns-overlap-1):\n",
    "            these_ind = (grouping_var>=bns[i-overlap]) | (grouping_var<=bns[i+overlap-n_bns])\n",
    "        else:\n",
    "            these_ind = (grouping_var>=bns[i-overlap])&(grouping_var<=bns[i+overlap]) # need to figure out \n",
    "            \n",
    "        if do_SDT:\n",
    "            dat_in = (var[these_ind],var2[these_ind])\n",
    "            fit = scipy.optimize.minimize(min_fun_gauss,prior_gauss,args=(dat_in,),bounds=((0.01,45),(-45,45)) )\n",
    "            out[:,i] = [fit.x[0],-fit.x[1]]\n",
    " \n",
    "        else:\n",
    "            if want_var==0:\n",
    "                out[i] = np.mean(var[these_ind])\n",
    "            elif want_var==1:\n",
    "                out[i] = np.std(var[these_ind])\n",
    "            elif want_var==2:\n",
    "                out[i] = circ_std(var[these_ind])\n",
    "            elif want_var==3:\n",
    "                out[i] = circ_mean(var[these_ind])\n",
    "            elif want_var==4:\n",
    "                out[i] = np.sum(wrap(var[these_ind]-circ_mean(var[these_ind]))**2)\n",
    "            \n",
    "    return out\n",
    "\n",
    "def wrap(x):\n",
    "    x[np.abs(x)>90]-=180*np.sign(x[np.abs(x)>90])\n",
    "    return x\n",
    "\n",
    "def wrap_rad(x):\n",
    "    x[np.abs(x)>pi]-=2*pi*np.sign(x[np.abs(x)>pi])\n",
    "    return x\n",
    "\n",
    "GUESS_RATE = 0.25\n",
    "# def min_fun_gauss(p):\n",
    "#     G = scipy.stats.norm(p[1],p[0])\n",
    "#     lik = ((1-obs)*G.cdf(d_use_rad)+(obs)*(1-G.cdf(d_use_rad)))*(1-GUESS_RATE)+0.5*GUESS_RATE\n",
    "#     return -np.sum(np.log(lik))\n",
    "\n",
    "def min_fun_gauss(p,dat_in):\n",
    "    # sd, bias\n",
    "    obs,d_use_deg = dat_in\n",
    "    G = scipy.stats.norm(p[1],p[0])\n",
    "    lik = ((1-obs)*G.cdf(d_use_deg)+(obs)*(1-G.cdf(d_use_deg)))*(1-GUESS_RATE)+0.5*GUESS_RATE\n",
    "    return -np.sum(np.log(lik))\n",
    "\n",
    "def gauss(x,mu=0,sig=1): return 1/np.sqrt(2*pi*sig**2)*np.exp(-((x-mu)**2)/(2*sig**2))\n",
    "def std_e(x): return np.std(x,0)/np.sqrt(len(x))\n",
    "def rectify(x):\n",
    "    if do_rectify:\n",
    "        return np.minimum(0,x)\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model defs\n",
    "def poisson_expect(expect,actual): return expect**actual/scipy.special.factorial(actual) * np.exp(-expect)\n",
    "def c(s_0,s_1=0,lam=10/90*pi,gamma=2): ## eq 7\n",
    "    full = np.exp(-1/(2*lam**2)*np.abs(wrap_rad(s_0-s_1))**gamma)\n",
    "    return full/np.sum(full,0)*len(s_0)\n",
    "\n",
    "def cf(s_0,s_1=0,lam=20/90*pi,gamma=2,p_same=0.64): ## eq 6  #10, 2, 0.9 (note p_same from BB&J2019 empiricial prior)\n",
    "    return p_same*c(s_0,s_1,lam,gamma) + (1-p_same)\n",
    "\n",
    "def run_model_1(p,data,min_mode='RSS',do_poisson=0):\n",
    "    # p - params \n",
    "    # data - dictionary\n",
    "    # min_mode \n",
    "    # do_poisson - flag, value is Rate\n",
    "    \n",
    "    gam_1, gam_s = p # unpack\n",
    "    this_ori_prev,this_ori_current,this_ori_dec = data['ori_prev'],data['ori_current'],data['ori_dec']\n",
    "\n",
    "    # implement adaptation on population\n",
    "#     adapt_shape = np.minimum(0,-gam_1*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s)**3) \n",
    "    adapt_shape = rectify(-gam_1*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s)**3)     #- adaptation shape (neuron x trial)\n",
    "    gamma_a =adapt_shape+gamma_n -np.mean(adapt_shape,0)*add_constant_adapt #- normalized gain (neuron x trial)\n",
    "    \n",
    "    resp_a_stim = gamma_a*np.exp(kappa_a*np.cos(wrap_rad(Phi-this_ori_current))-1)  #- adapted response (neuron x trial)\n",
    "    \n",
    "    if do_poisson:\n",
    "        ll_n_a_all = np.sum(np.log(poisson_expect(TC_n*do_poisson,np.expand_dims(resp_a_stim*do_poisson,2))),0)\n",
    "    else:\n",
    "        ll_n_a_all = np.sum(np.log(gauss(TC_n-np.expand_dims(resp_a_stim,2),0,sd)),0) # LL @ all ori (trial x orientation)\n",
    "\n",
    "    if min_mode=='RSS': #     for minimizing L2 error\n",
    "        max_lik = ori[np.argmax(ll_n_a_all,1)]\n",
    "        e_model = wrap_rad(max_lik-this_ori_dec)\n",
    "        RSS = np.mean(e_model**2)\n",
    "        return RSS\n",
    "    \n",
    "    if min_mode=='decode':\n",
    "        max_lik = ori[np.argmax(ll_n_a_all,1)]\n",
    "        return max_lik\n",
    "    \n",
    "    if min_mode=='vis':\n",
    "        max_lik = ori[np.argmax(ll_n_a_all,1)]\n",
    "        E_this = wrap_rad(max_lik-this_ori_current)*90/pi\n",
    "        return E_this\n",
    "\n",
    "def run_model_2(p,data,min_mode='maxlik_gauss',model_mode='a_a',do_poisson=0):\n",
    "    \n",
    "    this_ori_prev,this_ori_current,this_ori_dec = data['ori_prev'],data['ori_current'],data['ori_dec']\n",
    "    this_probe,this_resp = data['probe'], data['resp']\n",
    "    gam_1,gam_s = data['fit_1']\n",
    "    if model_mode!='a_a_2':\n",
    "        if do_poisson:\n",
    "            do_poisson,lam = p\n",
    "            sd = np.nan\n",
    "        else:\n",
    "            sd, lam = p\n",
    "        prior = cf(np.expand_dims(ori,1),s_1=this_ori_prev,lam=lam).T              # (trial x orientation)\n",
    "    elif model_mode=='a_a_2': # double aware\n",
    "        if do_poisson:\n",
    "            do_poisson=5\n",
    "        else:\n",
    "            sd = 0.15\n",
    "        gam_1_2, gam_s_2 = p\n",
    "        # adapt_shape_2 = np.minimum(0,-gam_1_2*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s_2)**3)    \n",
    "        adapt_shape_2 = rectify(-gam_1_2*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s_2)**3)       #- adaptation shape (neuron x trial)\n",
    "        gamma_a_2 =adapt_shape_2+gamma_n -np.expand_dims(np.mean(adapt_shape_2,0),0)*add_constant_adapt #- normalized gain (neuron x trial)\n",
    "        prior = 1 #- multiplicative identity\n",
    "        \n",
    "#     adapt_shape = np.minimum(0,-gam_1*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s)**3)    \n",
    "    adapt_shape = rectify(-gam_1*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s)**3)       #- adaptation shape (neuron x trial)\n",
    "    gamma_a =adapt_shape+gamma_n -np.expand_dims(np.mean(adapt_shape,0),0)*add_constant_adapt #- normalized gain (neuron x trial)\n",
    "    resp_a_stim = gamma_a*np.exp(kappa_a*np.cos(wrap_rad(Phi-this_ori_current))-1)  #- adapted response (neuron x trial)\n",
    "    \n",
    "    if model_mode=='a_a':\n",
    "        TC_a = np.expand_dims(gamma_a,2)*np.expand_dims(np.exp(kappa_a*np.cos(Phi-ori)-1),1) # expected response adapt ()\n",
    "        if do_poisson:\n",
    "            ll_a_a = np.sum(np.log(poisson_expect(TC_a*do_poisson,np.expand_dims(resp_a_stim*do_poisson,2))),0)\n",
    "        else:\n",
    "            ll_a_a = np.sum(np.log(gauss(TC_a-np.expand_dims(resp_a_stim,2),0,sd)),0)  # (trial x orientation)\n",
    "        ll_use = ll_a_a\n",
    "    elif model_mode=='a_n':\n",
    "        if do_poisson:\n",
    "            ll_a_n = np.sum(np.log(poisson_expect(TC_n*do_poisson,np.expand_dims(resp_a_stim*do_poisson,2))),0)\n",
    "        else:\n",
    "            ll_a_n = np.sum(np.log(gauss(TC_n-np.expand_dims(resp_a_stim,2),0,sd)),0)  # (trial x orientation)\n",
    "        ll_use = ll_a_n\n",
    "    elif model_mode=='a_a_2': # double aware\n",
    "        TC_a_2 = np.expand_dims(gamma_a_2,2)*np.expand_dims(np.exp(kappa_a*np.cos(Phi-ori)-1),1) # expected response adapt ()\n",
    "        if do_poisson:\n",
    "            ll_a_a_2 = np.sum(np.log(poisson_expect(TC_a_2*do_poisson,np.expand_dims(resp_a_stim*do_poisson,2))),0)\n",
    "        else:\n",
    "            ll_a_a_2 = np.sum(np.log(gauss(TC_a_2-np.expand_dims(resp_a_stim,2),0,sd)),0)  # (trial x orientation)\n",
    "        ll_use = ll_a_a_2\n",
    "    else: raise\n",
    "        \n",
    "    ll_use_cap = ll_use-np.expand_dims(np.max(ll_use,1),1)                     # prevent numerical underflow (set max lik==1)\n",
    "    posterior = np.exp(ll_use_cap)*prior\n",
    "    max_post = ori[np.argmax(posterior,1)] # MLE (trial)\n",
    "    \n",
    "    if min_mode=='maxlik_gauss': #   takes max likelihood and applies gaussian kernel\n",
    "        d_probe_post = wrap_rad(max_post-this_probe)*90/pi\n",
    "        G = scipy.stats.norm(0,fit_sd) # fit_sd fit_sd_eRecon\n",
    "        p_cw = G.cdf(d_probe_post)\n",
    "        lik = (p_cw*(this_resp==0)+(this_resp==1)*(1-p_cw))*(1-GUESS_RATE) + 0.5*GUESS_RATE\n",
    "        lik_resp  = np.sum(np.log(lik))\n",
    "        return -lik_resp\n",
    "    if min_mode == 'decode':\n",
    "        d_probe_post = wrap_rad(max_post-this_probe)*90/pi\n",
    "        G = scipy.stats.norm(0,fit_sd) # fit_sd fit_sd_eRecon\n",
    "        p_cw = G.cdf(d_probe_post)\n",
    "        lik = (p_cw*(this_resp==0)+(this_resp==1)*(1-p_cw))*(1-GUESS_RATE) + 0.5*GUESS_RATE\n",
    "        return lik\n",
    "    if min_mode == 'vis':\n",
    "        E_this = wrap_rad(max_post-this_ori_current)*90/pi\n",
    "        return E_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_sim_all(p,data,get_act=0):\n",
    "    # assume poisson\n",
    "    gam_1, gam_s = p[0]\n",
    "    do_poisson0,lam0 = p[1] # a_a\n",
    "    do_poisson1,lam1 = p[2] # a_n\n",
    "    gam_1_2, gam_s_2 = p[3] # a_a_2\n",
    "    this_ori_prev,this_ori_current,this_ori_dec = data['ori_prev'],data['ori_current'],data['ori_dec']\n",
    "    poisson_def = 5\n",
    "    \n",
    "    # encoding all\n",
    "    # adapt_shape = np.minimum(0,-gam_1*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s)**3)\n",
    "    adapt_shape = rectify(-gam_1*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s)**3)     #- adaptation shape (neuron x trial)\n",
    "    gamma_a =adapt_shape+gamma_n -np.expand_dims(np.mean(adapt_shape,0),0)*add_constant_adapt #- normalized gain (neuron x trial)\n",
    "    resp_a_stim = gamma_a*np.exp(kappa_a*np.cos(wrap_rad(Phi-this_ori_current))-1)\n",
    "    \n",
    "    if get_act:\n",
    "        resp_n_stim = gamma_n*np.exp(kappa_n*np.cos(wrap_rad(Phi-this_ori_current))-1)\n",
    "        return (np.sum(np.random.poisson(resp_n_stim*do_poisson),0),np.sum(np.random.poisson(resp_a_stim*do_poisson),0))\n",
    "    \n",
    "       \n",
    "    # encoding readout\n",
    "    resp_a_sim_enc =np.random.poisson(resp_a_stim*poisson_def)\n",
    "    ll_n_a_enc = np.sum(np.log(poisson_expect(TC_n*poisson_def, np.expand_dims(resp_a_sim_enc,2))),0) # LL @ all ori (trial x orientation)\n",
    "    TC_a = np.expand_dims(gamma_a,2)*np.expand_dims(np.exp(kappa_a*np.cos(Phi-ori)-1),1) # expected response adapt ()\n",
    "    \n",
    "    # prior\n",
    "    prior0 = cf(np.expand_dims(ori,1),s_1=this_ori_prev,lam=lam0).T              # (trial x orientation)\n",
    "    prior1 = cf(np.expand_dims(ori,1),s_1=this_ori_prev,lam=lam1).T              # (trial x orientation)\n",
    "    \n",
    "    # a_a\n",
    "    resp_a_sim_a_a =np.random.poisson(resp_a_stim*do_poisson0)\n",
    "    ll_a_a_dec = np.sum(np.log(poisson_expect(TC_a*do_poisson0,np.expand_dims(resp_a_sim_a_a,2))),0)\n",
    "    \n",
    "    # a_n\n",
    "    resp_a_sim_a_n =np.random.poisson(resp_a_stim*do_poisson1)\n",
    "    ll_n_a_dec = np.sum(np.log(poisson_expect(TC_n*do_poisson1, np.expand_dims(resp_a_sim_a_n,2))),0) # LL @ all ori (trial x orientation)\n",
    "    \n",
    "    # a_a_2\n",
    "#     adapt_shape_2 = np.minimum(0,-gam_1_2*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s_2)**3)   \n",
    "    adapt_shape_2 = rectify(-gam_1_2*np.cos(wrap_rad(Phi-this_ori_prev)*gam_s_2)**3)       #- adaptation shape (neuron x trial)\n",
    "    gamma_a_2 =adapt_shape_2+gamma_n -np.expand_dims(np.mean(adapt_shape_2,0),0)*add_constant_adapt #- normalized gain (neuron x trial)\n",
    "    TC_a_2 = np.expand_dims(gamma_a_2,2)*np.expand_dims(np.exp(kappa_a*np.cos(Phi-ori)-1),1) # expected response adapt ()\n",
    "    ll_a_a_2_dec = np.sum(np.log(poisson_expect(TC_a_2*poisson_def,np.expand_dims(resp_a_sim_enc,2))),0)\n",
    "    \n",
    "    ll_all = [ll_n_a_enc,ll_a_a_dec,ll_n_a_dec,ll_a_a_2_dec]\n",
    "    ll_all_cap = [l - np.expand_dims(np.max(l,1),1) for l in ll_all]\n",
    "    prior_all = [1,prior0,prior1,1]\n",
    "    post_all = [np.exp(ll_all_cap[i])*prior_all[i] for i in range(4)]\n",
    "    max_ll_all = [ori[np.argmax(post,1)] for post in post_all]\n",
    "    E_all = [wrap_rad(this_maxLL-this_ori_current)*90/pi for this_maxLL in max_ll_all]\n",
    "    return E_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_units=100\n",
    "N_stim=91\n",
    "N_probe=720 # 'resolution of model', 360 is good, go higher (1440) for publication quality figs\n",
    "\n",
    "kappa_n = 1.0 # (0.25) # note this is wider than normal units but fine here for simplicity\n",
    "gamma_n = 1.0\n",
    "kappa_1 = 0.0\n",
    "kappa_a = kappa_n\n",
    "                              \n",
    "Phi = np.expand_dims(np.linspace(-pi,pi-(2*pi/N_units),N_units),1) #- tuning curve centers\n",
    "theta_n = np.linspace(-pi,pi-(pi/N_stim),N_stim)[::-1]           #- stimulus probes\n",
    "ori = np.linspace(-pi,pi-(pi/N_probe),N_probe)                   #- stimuli to sample for likelihood\n",
    "\n",
    "# for model visualization\n",
    "theta_n1 = 0 # adapting stim (rad) \n",
    "resp_n = gamma_n*np.exp(kappa_n*np.cos(wrap_rad(Phi-theta_n))-1)  #- non-adapted response (for vis model)\n",
    "TC_n = np.expand_dims(gamma_n*np.exp(kappa_n*np.cos(wrap_rad(Phi-ori))-1),1) # expected non-adapted response (for vis model)\n",
    "\n",
    "default_var = {'gam_1':0.15,'gam_s':0.6,'sd':0.15,'lam':0.6}\n",
    "# ranges_brute = (((0.00,0.9),(0.2,1.0)),  # P1\n",
    "#                 ((0.05,0.50),(0.1,0.9)), # P2\n",
    "#                 ((0.05,0.50),(0.1,0.9)), # P2 unaware\n",
    "#                 ((0.00,0.90),(0.2,1.0))) # P2 overaware\n",
    "\n",
    "# ranges_brute_poisson = (((0.1,0.9),(0.2,1.5)),  # P1\n",
    "#                 ((5,45),(0.1,1.0)), # P2\n",
    "#                 ((5,45),(0.1,1.0)), # P2 unaware\n",
    "#                 ((0.1,0.90),(0.2,1.5))) # P2 overaware\n",
    "\n",
    "ranges_brute_poisson = (((0.1,0.9),(0.1,1.5)),  # P1\n",
    "                ((.5,10),(0.1,1.1)), # P2\n",
    "                ((.01,10),(0.1,1.5)), # P2 unaware\n",
    "                ((0.1,0.90),(0.1,1.5))) # P2 overaware\n",
    "\n",
    "def_vals_poisson = ((0.3,1.0),(10.0,0.5),(0.5,1.0),(0.5,1.0))\n",
    "N_brute = 8\n",
    "sd = 0.15 # default\n",
    "add_constant_adapt = 0\n",
    "do_rectify = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CV Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make key parts into a function that can be parallelized\n",
    "do_poisson = 5\n",
    "if do_poisson:\n",
    "    ranges_brute_use = ranges_brute_poisson\n",
    "else:\n",
    "    ranges_brute_use = ranges_brute\n",
    "def do_CV(g):\n",
    "\n",
    "    print(g, 'Starting')\n",
    "    these_ind = G!=g\n",
    "    data_in = {'ori_prev':ori_prev[:,these_ind],'ori_current':ori_current[these_ind],'ori_dec':ori_dec[these_ind],\n",
    "               'probe':probe[these_ind],'resp':resp[these_ind]}\n",
    "    \n",
    "    # Brute --> NM\n",
    "    out_brute_1 = scipy.optimize.brute(run_model_1,ranges_brute_use[0],Ns=N_brute,args=(data_in,'RSS',do_poisson),finish=None)\n",
    "    out_this_1 = scipy.optimize.minimize(run_model_1,out_brute_1,args=(data_in,'RSS',do_poisson),method='Nelder-mead')\n",
    "    print(g, 'part 1 complete')\n",
    "\n",
    "    data_in['fit_1'] = out_this_1.x\n",
    "    out_brute_2 = scipy.optimize.brute(run_model_2,ranges_brute_use[1],Ns=N_brute,args=(data_in,'maxlik_gauss','a_a',do_poisson),finish=None)\n",
    "    out_this_2 = scipy.optimize.minimize(run_model_2,out_brute_2,args=(data_in,'maxlik_gauss','a_a',do_poisson),method='Nelder-mead')\n",
    "    \n",
    "    print(g, 'part 2 standard complete')\n",
    "    out_brute_2_ua = scipy.optimize.brute(run_model_2,ranges_brute_use[2],Ns=N_brute,args=(data_in,'maxlik_gauss','a_n',do_poisson),finish=None)\n",
    "    out_this_2_ua = scipy.optimize.minimize(run_model_2,out_brute_2_ua,args=(data_in,'maxlik_gauss','a_n',do_poisson),method='Nelder-mead')\n",
    "    \n",
    "    print(g, 'part 2 unaware complete')\n",
    "    out_brute_2_oa = scipy.optimize.brute(run_model_2,ranges_brute_use[3],Ns=N_brute,args=(data_in,'maxlik_gauss','a_a_2',do_poisson),finish=None)\n",
    "    out_this_2_oa = scipy.optimize.minimize(run_model_2,out_brute_2_oa,args=(data_in,'maxlik_gauss','a_a_2',do_poisson),method='Nelder-mead')\n",
    "    \n",
    "    print(g, 'part 2 overaware complete')\n",
    "    return (out_this_1,out_this_2,out_this_2_ua,out_this_2_oa)\n",
    "#     return (out_this_1.x,out_this_2.x,out_this_2_ua.x,out_this_2_oa.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit with finer sampling over brute!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run each CV/ model efficiently/ in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a450180e1c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_this_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mn_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mn_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_g\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mnPool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "# run part 1\n",
    "def job_runner_1(g):\n",
    "    print(g)\n",
    "    these_ind = G!=g\n",
    "    data_in = {'ori_prev':ori_prev[:,these_ind],'ori_current':ori_current[these_ind],'ori_dec':ori_dec[these_ind],\n",
    "           'probe':probe[these_ind],'resp':resp[these_ind]}\n",
    "    this_start = all_brute_runs[int(g),0,:]\n",
    "    this_fit = scipy.optimize.minimize(run_model_1,this_start,args=(data_in,'RSS',do_poisson),method='Nelder-mead')\n",
    "    print(g,'Done')\n",
    "    return this_fit\n",
    "\n",
    "# run parts 2-4\n",
    "def job_runner(ind): # all decoding laps\n",
    "    g = ind%n_g\n",
    "    this_job = ind//n_g\n",
    "    these_params = all_brute_runs[int(g),this_job+1,:]\n",
    "\n",
    "    these_ind = G!=g\n",
    "    data_in = {'ori_prev':ori_prev[:,these_ind],'ori_current':ori_current[these_ind],'ori_dec':ori_dec[these_ind],\n",
    "           'probe':probe[these_ind],'resp':resp[these_ind]}\n",
    "    data_in['fit_1'] = part_1_params[g]\n",
    "    \n",
    "    if this_job==0: # B-A\n",
    "        out_this_2 = scipy.optimize.minimize(run_model_2,these_params,args=(data_in,'maxlik_gauss','a_a',do_poisson),method='Nelder-mead')\n",
    "    elif this_job==1: # B-uA\n",
    "        out_this_2 = scipy.optimize.minimize(run_model_2,these_params,args=(data_in,'maxlik_gauss','a_n',do_poisson),method='Nelder-mead')\n",
    "    elif this_job==2:\n",
    "        out_this_2 = scipy.optimize.minimize(run_model_2,these_params,args=(data_in,'maxlik_gauss','a_a_2',do_poisson),method='Nelder-mead')\n",
    "    print(g,this_job,out_this_2.x)\n",
    "    return out_this_2\n",
    "\n",
    "n_g = len(np.unique(G))\n",
    "n_job = n_g*3\n",
    "nPool = 30\n",
    "N_brute = 30\n",
    "\n",
    "# run brute fit for all CV/models\n",
    "all_brute_runs = []\n",
    "for g in np.unique(G):\n",
    "    print(g)\n",
    "    these_ind = G!=g\n",
    "    data_in = {'ori_prev':ori_prev[:,these_ind],'ori_current':ori_current[these_ind],'ori_dec':ori_dec[these_ind],\n",
    "               'probe':probe[these_ind],'resp':resp[these_ind]}\n",
    "\n",
    "    out_brute_1 = scipy.optimize.brute(run_model_1,ranges_brute_use[0],Ns=N_brute,args=(data_in,'RSS',do_poisson),finish=None,workers=nPool)\n",
    "   \n",
    "    print(g, 'part 1 complete')\n",
    "    data_in['fit_1'] = out_this_1.x\n",
    "    out_brute_2 = scipy.optimize.brute(run_model_2,ranges_brute_use[1],Ns=N_brute,args=(data_in,'maxlik_gauss','a_a',do_poisson),finish=None,workers=nPool)\n",
    "   \n",
    "    print(g, 'part 2 aware complete')\n",
    "    out_brute_2_ua = scipy.optimize.brute(run_model_2,ranges_brute_use[2],Ns=N_brute,args=(data_in,'maxlik_gauss','a_n',do_poisson),finish=None,workers=nPool)\n",
    "  \n",
    "    print(g, 'part 2 unaware complete')\n",
    "    out_brute_2_oa = scipy.optimize.brute(run_model_2,ranges_brute_use[3],Ns=N_brute,args=(data_in,'maxlik_gauss','a_a_2',do_poisson),finish=None,workers=nPool)\n",
    "    \n",
    "    print(g, 'part 2 overaware complete')\n",
    "\n",
    "    all_brute_runs.append((out_brute_1,out_brute_2,out_brute_2_ua,out_brute_2_oa))\n",
    "all_brute_runs = np.array(all_brute_runs)\n",
    "\n",
    "# run fine tune fit for P1\n",
    "with Pool(n_g) as pool:\n",
    "    fit_part_1 = pool.map(job_runner_1,np.unique(G))\n",
    "part_1_params = np.array([f.x for f in fit_part_1])\n",
    "\n",
    "# run fine tune fit for P2-4\n",
    "with Pool(20) as pool:\n",
    "    fit_part_2 = pool.map(job_runner,range(n_job))\n",
    "    \n",
    "final_fits_part_2 = np.array([f.x for f in fit_part_2]).reshape(3,n_g,2)\n",
    "params = np.swapaxes(np.concatenate((np.expand_dims(part_1_params,0),final_fits_part_2)),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_pickle('DAT_IEM_COMPRESS')\n",
    "\n",
    "d_ori = np.concatenate(([0],wrap(dat.orient0[:-1].values - dat.orient0[1:].values)))\n",
    "d_ori[dat.trial==0] = np.nan\n",
    "dat['d_ori']=d_ori\n",
    "d_stim = wrap(dat.orient0.values-dat.orient1.values)\n",
    "dat['d_stim'] = d_stim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select subject/ ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-5a12b18321f4>:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  DEC_ALL = pd.Series()\n",
      "<ipython-input-21-5a12b18321f4>:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  dec_subj = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCSD054\n",
      "0.0\n",
      "0.0 part 1 complete\n",
      "0.0 part 2 aware complete\n",
      "0.0 part 2 unaware complete\n",
      "0.0 part 2 overaware complete\n",
      "1.0\n",
      "1.0 part 1 complete\n",
      "1.0 part 2 aware complete\n",
      "1.0 part 2 unaware complete\n",
      "1.0 part 2 overaware complete\n",
      "2.0\n",
      "2.0 part 1 complete\n",
      "2.0 part 2 aware complete\n",
      "2.0 part 2 unaware complete\n",
      "2.0 part 2 overaware complete\n",
      "3.0\n",
      "3.0 part 1 complete\n",
      "3.0 part 2 aware complete\n",
      "3.0 part 2 unaware complete\n",
      "3.0 part 2 overaware complete\n",
      "4.0\n",
      "4.0 part 1 complete\n",
      "4.0 part 2 aware complete\n",
      "4.0 part 2 unaware complete\n",
      "4.0 part 2 overaware complete\n",
      "5.0\n",
      "5.0 part 1 complete\n",
      "5.0 part 2 aware complete\n",
      "5.0 part 2 unaware complete\n",
      "5.0 part 2 overaware complete\n",
      "6.0\n",
      "6.0 part 1 complete\n",
      "6.0 part 2 aware complete\n",
      "6.0 part 2 unaware complete\n",
      "6.0 part 2 overaware complete\n",
      "7.0\n",
      "7.0 part 1 complete\n",
      "7.0 part 2 aware complete\n",
      "7.0 part 2 unaware complete\n",
      "7.0 part 2 overaware complete\n",
      "8.0\n",
      "8.0 part 1 complete\n",
      "8.0 part 2 aware complete\n",
      "8.0 part 2 unaware complete\n",
      "8.0 part 2 overaware complete\n",
      "9.0\n",
      "9.0 part 1 complete\n",
      "9.0 part 2 aware complete\n",
      "9.0 part 2 unaware complete\n",
      "9.0 part 2 overaware complete\n",
      "10.0\n",
      "10.0 part 1 complete\n",
      "10.0 part 2 aware complete\n",
      "10.0 part 2 unaware complete\n",
      "10.0 part 2 overaware complete\n",
      "11.0\n",
      "11.0 part 1 complete\n",
      "11.0 part 2 aware complete\n",
      "11.0 part 2 unaware complete\n",
      "11.0 part 2 overaware complete\n",
      "12.0\n",
      "12.0 part 1 complete\n",
      "12.0 part 2 aware complete\n",
      "12.0 part 2 unaware complete\n",
      "12.0 part 2 overaware complete\n",
      "3.05.07.00.02.010.09.08.01.04.011.06.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12.0\n",
      "1.0 Done\n",
      "2.0 Done\n",
      "11.0 Done\n",
      "4.0 Done\n",
      "9.0 Done\n",
      "0.0 Done\n",
      "8.0 Done\n",
      "12.0 Done\n",
      "10.0 Done\n",
      "6.0 Done\n",
      "5.0 Done\n",
      "7.0 Done\n",
      "3.0 Done\n",
      "10 0 [1.66670125 0.62492442]\n",
      "6 0 [1.28773872 0.60663818]\n",
      "1 1 [0.01248623 3.79545706]\n",
      "1 0 [1.63630507 0.65618374]\n",
      "11 0 [2.6317664  0.57234062]\n",
      "0 0 [1.41973628 0.59846792]\n",
      "8 0 [1.33182458 0.62509125]\n",
      "4 0 [1.37505209 0.58621466]\n",
      "2 0 [1.83540026 0.62976774]\n",
      "0 1 [0.0125564  2.91914248]\n",
      "6 1 [0.01290111 3.06210495]\n",
      "5 0[1.3952908  0.58276557] \n",
      "3 1 [0.01292179 3.72450262]\n",
      "7 0 [1.81940019 0.61201557]\n",
      "2 1 [0.01266038 3.84979253]\n",
      "5 1 [0.01432513 2.76925913]\n",
      "9 0 [1.83125271 0.61396715]\n",
      "12 0 [1.24531277 0.60946617]\n",
      "3 0 [2.11310407 0.56968503]\n",
      "4 1 [0.01425731 2.69180167]\n",
      "7 1 [0.01339484 3.6046414 ]\n",
      "9 1 [0.0129437  3.63412464]\n",
      "0 2 [0.72517234 0.53389112]\n",
      "12 1 [0.01250683 2.91958724]\n",
      "11 1 [0.01260875 3.9503626 ]\n",
      "7 2 [0.51987689 0.42758641]\n",
      "5 2 [0.73120155 0.52031344]\n",
      "2 2 [0.50104961 0.40363043]\n",
      "10 1 [0.01269591 3.61467126]\n",
      "3 2 [0.50606272 0.42594041]\n",
      "4 2 [0.73584565 0.54216193]\n",
      "8 1 [0.0138076  2.89921541]\n",
      "1 2 [0.49421132 0.44144246]\n",
      "11 2 [0.47842509 0.43165036]\n",
      "6 2 [0.67551142 0.50247269]\n",
      "10 2 [0.51619877 0.44759744]\n",
      "9 2 [0.51501545 0.44296926]\n",
      "12 2 [0.73675054 0.5249913 ]\n",
      "8 2 [0.69547981 0.53848351]\n",
      "UCSD060\n",
      "0.0\n",
      "0.0 part 1 complete\n",
      "0.0 part 2 aware complete\n",
      "0.0 part 2 unaware complete\n",
      "0.0 part 2 overaware complete\n",
      "1.0\n",
      "1.0 part 1 complete\n",
      "1.0 part 2 aware complete\n",
      "1.0 part 2 unaware complete\n",
      "1.0 part 2 overaware complete\n",
      "2.0\n",
      "2.0 part 1 complete\n",
      "2.0 part 2 aware complete\n",
      "2.0 part 2 unaware complete\n",
      "2.0 part 2 overaware complete\n",
      "3.0\n",
      "3.0 part 1 complete\n",
      "3.0 part 2 aware complete\n",
      "3.0 part 2 unaware complete\n",
      "3.0 part 2 overaware complete\n",
      "4.0\n",
      "4.0 part 1 complete\n",
      "4.0 part 2 aware complete\n",
      "4.0 part 2 unaware complete\n",
      "4.0 part 2 overaware complete\n",
      "5.0\n",
      "5.0 part 1 complete\n",
      "5.0 part 2 aware complete\n",
      "5.0 part 2 unaware complete\n",
      "5.0 part 2 overaware complete\n",
      "6.0\n",
      "6.0 part 1 complete\n",
      "6.0 part 2 aware complete\n",
      "6.0 part 2 unaware complete\n",
      "6.0 part 2 overaware complete\n",
      "7.0\n",
      "7.0 part 1 complete\n",
      "7.0 part 2 aware complete\n",
      "7.0 part 2 unaware complete\n",
      "7.0 part 2 overaware complete\n",
      "8.0\n",
      "8.0 part 1 complete\n",
      "8.0 part 2 aware complete\n",
      "8.0 part 2 unaware complete\n",
      "8.0 part 2 overaware complete\n",
      "9.0\n",
      "9.0 part 1 complete\n",
      "9.0 part 2 aware complete\n",
      "9.0 part 2 unaware complete\n",
      "9.0 part 2 overaware complete\n",
      "10.0\n",
      "10.0 part 1 complete\n",
      "10.0 part 2 aware complete\n",
      "10.0 part 2 unaware complete\n",
      "10.0 part 2 overaware complete\n",
      "11.0\n",
      "11.0 part 1 complete\n",
      "11.0 part 2 aware complete\n",
      "11.0 part 2 unaware complete\n",
      "11.0 part 2 overaware complete\n",
      "12.0\n",
      "12.0 part 1 complete\n",
      "12.0 part 2 aware complete\n",
      "12.0 part 2 unaware complete\n",
      "12.0 part 2 overaware complete\n",
      "5.01.011.010.02.07.08.06.09.00.03.04.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_bns = 91\n",
    "overlap = 4 \n",
    "bns = np.linspace(-90,90,n_bns)\n",
    "\n",
    "DEC_ALL = pd.Series()\n",
    "MF = pd.DataFrame()\n",
    "do_poisson = 5\n",
    "\n",
    "\n",
    "for subj in subjs:\n",
    "    dec_subj = pd.Series()\n",
    "    for roi in rois[2:3]:#rois[2:3]:\n",
    "        print(subj)\n",
    "\n",
    "        SA = dat[(dat.subj==subj)]#&(dat.trial!=1)]\n",
    "        good = (SA.trial!=1)&(~np.isnan(SA.respCW))\n",
    "\n",
    "        # get CV group\n",
    "        sess_u=SA.sess.unique()\n",
    "        n_sess = len(sess_u)\n",
    "        G_task=np.ones(len(SA))\n",
    "        for i,gi in enumerate(np.arange(0,n_sess,4)):\n",
    "            G_task[np.isin(SA.sess,sess_u[gi:gi+4])] = i\n",
    "        G = G_task[good] # CV Groups!\n",
    "        n_g = len(np.unique(G))\n",
    "\n",
    "        ori_current = (SA.orient0.values/90*pi)[good]\n",
    "        ori_prev = np.expand_dims(np.concatenate(([0],SA.orient0[:-1].values))/90*pi,0)[:,good]\n",
    "        ori_dec = (SA['estIEM'+roi].values/90*pi-pi)[good]\n",
    "        #         d_ori = wrap_rad(ori_prev.flatten()-ori_current)\n",
    "        d_ori = SA['d_ori'].values[good]\n",
    "        probe = SA.orient1.values[good]/90*pi\n",
    "        resp = SA.respCW.values[good]\n",
    "        eRecon = wrap(SA['estIEM'+roi].values-SA['orient0'].values-90)[good]\n",
    "        obs = SA.respCW.values[good]\n",
    "        d_use_deg = SA['d_stim'].values[good] # need to be in deg for gaussian\n",
    "\n",
    "        obs_flip = obs.copy()*1\n",
    "        obs_flip[d_ori<0] = 1-obs_flip[d_ori<0]\n",
    "        d_use_deg_flip = d_use_deg.copy()\n",
    "        d_use_deg_flip[d_ori<0] = d_use_deg_flip[d_ori<0]*-1\n",
    "\n",
    "        out_percept = do_bining(bns,overlap,d_ori,resp,d_use_deg,prior_gauss=(3,0))\n",
    "        out_neural = do_bining(bns,overlap,d_ori,eRecon)\n",
    "\n",
    "        p_gauss = (4,0)\n",
    "        dat_in = (obs_flip,d_use_deg_flip)\n",
    "        fit_gauss = scipy.optimize.minimize(min_fun_gauss,p_gauss,args=(dat_in,),method='Nelder-Mead')\n",
    "        fit_sd,fit_bias = fit_gauss.x\n",
    "        ## - here putting in code (don't want to be in function)\n",
    "\n",
    "        ### my block\n",
    "        n_g = len(np.unique(G))\n",
    "        n_job = n_g*3\n",
    "        nPool = 30\n",
    "        N_brute = 10\n",
    "\n",
    "        # run brute fit for all CV/models\n",
    "        all_brute_runs = []\n",
    "        for g in np.unique(G):\n",
    "            print(g)\n",
    "            these_ind = G!=g\n",
    "            data_in = {'ori_prev':ori_prev[:,these_ind],'ori_current':ori_current[these_ind],'ori_dec':ori_dec[these_ind],\n",
    "                       'probe':probe[these_ind],'resp':resp[these_ind]}\n",
    "\n",
    "            out_brute_1 = scipy.optimize.brute(run_model_1,ranges_brute_use[0],Ns=N_brute,args=(data_in,'RSS',do_poisson),finish=None,workers=nPool)\n",
    "\n",
    "            print(g, 'part 1 complete')\n",
    "            data_in['fit_1'] = out_brute_1\n",
    "            out_brute_2 = scipy.optimize.brute(run_model_2,ranges_brute_use[1],Ns=N_brute,args=(data_in,'maxlik_gauss','a_a',do_poisson),finish=None,workers=nPool)\n",
    "\n",
    "            print(g, 'part 2 aware complete')\n",
    "            out_brute_2_ua = scipy.optimize.brute(run_model_2,ranges_brute_use[2],Ns=N_brute,args=(data_in,'maxlik_gauss','a_n',do_poisson),finish=None,workers=nPool)\n",
    "\n",
    "            print(g, 'part 2 unaware complete')\n",
    "            out_brute_2_oa = scipy.optimize.brute(run_model_2,ranges_brute_use[3],Ns=N_brute,args=(data_in,'maxlik_gauss','a_a_2',do_poisson),finish=None,workers=nPool)\n",
    "\n",
    "            print(g, 'part 2 overaware complete')\n",
    "\n",
    "            all_brute_runs.append((out_brute_1,out_brute_2,out_brute_2_ua,out_brute_2_oa))\n",
    "        all_brute_runs = np.array(all_brute_runs)\n",
    "\n",
    "        # run fine tune fit for P1\n",
    "        with Pool(n_g) as pool:\n",
    "            fit_part_1 = pool.map(job_runner_1,np.unique(G))\n",
    "        part_1_params = np.array([f.x for f in fit_part_1])\n",
    "\n",
    "        # run fine tune fit for P2-4\n",
    "        with Pool(20) as pool:\n",
    "            fit_part_2 = pool.map(job_runner,range(n_job))\n",
    "\n",
    "        final_fits_part_2 = np.array([f.x for f in fit_part_2]).reshape(3,n_g,2)\n",
    "        params = np.swapaxes(np.concatenate((np.expand_dims(part_1_params,0),final_fits_part_2)),0,1)\n",
    "        ### my block\n",
    "\n",
    "        data = {'ori_prev':ori_prev,'ori_current':ori_current,'ori_dec':ori_dec,\n",
    "               'probe':probe,'resp':resp}\n",
    "\n",
    "        dec_ori,lik_resp,dec_resp = np.zeros(len(ori_current)),np.zeros((3,len(ori_current))),np.zeros((3,len(ori_current)))\n",
    "        for g in range(n_g):\n",
    "            these_ind = G==g\n",
    "            data_in = {'ori_prev':ori_prev[:,these_ind],'ori_current':ori_current[these_ind],'ori_dec':ori_dec[these_ind],\n",
    "                       'probe':probe[these_ind],'resp':resp[these_ind]}\n",
    "\n",
    "            data_in['fit_1'] = params[g,0,:]\n",
    "\n",
    "            dec_ori[these_ind] = run_model_1(params[g,0,:],data_in,min_mode='decode')\n",
    "            lik_resp[0,these_ind] = run_model_2(params[g,1,:],data_in,min_mode='decode',model_mode='a_a',do_poisson=do_poisson)\n",
    "            lik_resp[1,these_ind] = run_model_2(params[g,2,:],data_in,min_mode='decode',model_mode='a_n',do_poisson=do_poisson)\n",
    "            lik_resp[2,these_ind] = run_model_2(params[g,3,:],data_in,min_mode='decode',model_mode='a_a_2',do_poisson=do_poisson)\n",
    "\n",
    "            dec_resp[0,these_ind] = run_model_2(params[g,1,:],data_in,min_mode='vis',model_mode='a_a',do_poisson=do_poisson)\n",
    "            dec_resp[1,these_ind] = run_model_2(params[g,2,:],data_in,min_mode='vis',model_mode='a_n',do_poisson=do_poisson)\n",
    "            dec_resp[2,these_ind] = run_model_2(params[g,3,:],data_in,min_mode='vis',model_mode='a_a_2',do_poisson=do_poisson)\n",
    "\n",
    "        cv_lik = np.sum(np.log(lik_resp),1)\n",
    "\n",
    "        RMSE = np.sqrt(np.mean((wrap_rad(dec_ori-ori_dec)*90/pi)**2))\n",
    "        RMSE_null = np.sqrt(np.mean((wrap_rad(ori_dec-ori_current)*90/pi)**2))\n",
    "\n",
    "        lik_null = np.sum(np.log((((resp==0)*[d_ori>0]) + ((resp==1)*[d_ori<0]))*(1-GUESS_RATE) +0.5*GUESS_RATE))\n",
    "\n",
    "        this_dec = pd.Series({'data':data,'G':G,'params':params, 'dec_ori':dec_ori,'lik_resp':lik_resp,'dec_resp':dec_resp,\n",
    "                             'neural_bias':out_neural,'percept_bias':out_percept,'do_poisson':do_poisson,'eRecon':eRecon})\n",
    "        dec_subj[roi] = this_dec\n",
    "    \n",
    "        MF = MF.append({'subj':subj,'roi':roi,'RMSE':RMSE,'RMSE_null':RMSE_null,'lik_a_a_p':cv_lik[0],\n",
    "                        'lik_a_n_p':cv_lik[1],'lik_a_a_2':cv_lik[2],'lik_null':lik_null},ignore_index=1)\n",
    "    DEC_ALL[subj] = dec_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UCSD054    V3    data            {'ori_prev': [[3.0479382...\n",
       "UCSD060    V3    data            {'ori_prev': [[3.0479382...\n",
       "UCSD061    V3    data            {'ori_prev': [[3.0479382...\n",
       "UCSD062    V3    data            {'ori_prev': [[3.0479382...\n",
       "UCSD063    V3    data            {'ori_prev': [[1.3356446...\n",
       "UCSD064    V3    data            {'ori_prev': [[3.0479382...\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEC_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "this_d = {}\n",
    "for subj in DEC_ALL.keys():\n",
    "    this_d[subj] = dict(DEC_ALL[subj]['V3'])\n",
    "# pickle.dump(this_d,open('ModelFitsV3.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done, analyze fits in other notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
